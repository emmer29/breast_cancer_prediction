# -*- coding: utf-8 -*-
"""breast_cancer_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Od37aH3M1pxk4VNYm7qgO8wibvti3t1r

<h3>BREAST CANCER PREDICTION USING LOGISTIC REGRESSION<h3>

<p1>The objective of this project is to analyze and classify breast tumors as malignant or benign using machine learning techniques, specifically logistic regression. The Breast Cancer Wisconsin (Diagnostic) Dataset is used for this purpose.<p1>

<p1>Breast cancer is a prevalent form of cancer among women, accounting for a significant percentage of all cancer cases worldwide. Detecting and classifying tumors as cancerous (malignant) or non-cancerous (benign) is crucial for accurate diagnosis and treatment.<p1>

<p1>The dataset provides features related to breast tumor characteristics, such as texture, perimeter, area, smoothness, and more. The challenge is to develop classification models that can accurately predict the type of cancer based on these features.<p1>

<p1>We will try to understand, explore and cleanup the dataset. Next we will build a logistic regression model, a statistical technique used for binary classification. We will train the model on the dataset, using the features to predict whether a tumor is malignant or benign.

Hyperparameters of the model will also be tuned, to optimize its performance. We will adjust parameters such as the regularization strength, solver algorithm, and maximum number of iterations to enhance the model's accuracy.

The performance of the logistic regression model will be done using evaluation metrics such as accuracy, precision, recall, and F1-score. These metrics provide insights into the model's ability to correctly classify malignant and benign tumors.<p1>
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, roc_auc_score

#read the data
data = pd.read_csv('/content/breast-cancer.csv')

#check the first three rows of the data set
data.head(3)

# check some statistical description of the data
data.describe()

"""<p1>We will create an extra column to have our class 0 and 1. 0 to represent malignant cases and 1 to represent benign cases<p1>"""

data['label'] = data['diagnosis'].apply(lambda x: 1 if x == 'B' else 0)

# check data information 
data.info()

"""<h3>Exploratory Data Analysis<h3>
<p1>We try to ascertain the percentage of malignant cases to benign cases.<p1>
"""

#count the values of bening and malignant
data['label'].value_counts()

# get the percentage of malignant and bening cases
percentage_1s = (data['label'] == 1).mean() * 100
percentage_0s = (data['label'] == 0).mean() * 100

# Print the percentages
print(f"Percentage of 1s: {percentage_1s:.2f}%")
print(f"Percentage of 0s: {percentage_0s:.2f}%")

"""next lets group the features according to the labels, and take the mean. We will further drop the ID column since its a unique ID that identifies the patients or samples and not necessarily an important feature."""

# drop column ID
data = data.drop('id', axis=1)
data = data.drop('diagnosis', axis=1)

# grouping the features.
data.groupby('label').mean()

"""<h3>Creating Input Features, Split and Train Dataset<h3>

<p1>On visual inspection we can see that in certain features, the values in the malignant cases are somewhat higher than in benign cases.
Next we set our input features and target features. The input features are our x variables and the target variables is our y variable. We also drop the diagnosis column because it is a category variable and will raise error when being computed on the model.<p1>
"""

# creating input and target features
X = data.drop('label', axis=1)
y = data['label']

# create test and training set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Next we train our model. In the constructor for the logistic regression model, we will use the solver liblinear to avoid non convergence problems. It can be a good choice, especially when dealing with binary classification problems.

The 'liblinear' solver is specifically designed for logistic regression and can handle both L1 and L2 regularization. It works well for small to medium-sized datasets and is generally a reliable solver choice for binary classification tasks.
"""

# Create an instance of the logistic regression model
logreg = LogisticRegression(solver='liblinear', max_iter=25)


# Fit the model to the training data
logreg.fit(X_train, y_train)

# Predict labels for the test data
y_pred = logreg.predict(X_test)

# Calculate accuracy on the test data
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""The accuracy score indicates the proportion of correctly predicted labels compared to the total number of samples in the test data. By comparing the predicted labels (y_pred) with the true labels (y_test), the accuracy score is helps you assess how well the model is performing on the test data.

It's important to note that accuracy alone might not provide the complete picture of a model's performance, especially in imbalanced datasets. It's often useful to consider other evaluation metrics such as precision, recall, or F1 score to gain a more comprehensive understanding of the model's behavior.

Overall, obtaining a high accuracy score indicates that the logistic regression model is performing well on the test data.

Next we will build a predictive system where we can supply input X and allow the system predict a class or label, that is if the tumour is malignant or benign.
"""

#create an input array
input_data = (13.54,14.36,87.46,566.3,0.09779,0.08129,0.06664,0.04781,0.1885,0.05766,0.2699,0.7886,2.058,23.56,0.008462,0.0146,0.02387,0.01315,0.0198,0.0023,15.11,19.26,99.7,711.2,0.144,0.1773,0.239,0.1288,0.2977,0.07259)
input_data_as_np = np.asarray(input_data)
input_data_reshaped = input_data_as_np.reshape(1,-1)

"""Reshaping an array does not simply mean adding a column to a vector. It involves changing the shape or dimensions of the array while maintaining the total number of elements.

When reshaping an array, the shape of the array is modified, which can involve changing the number of rows and columns. The reshaping operation reorganizes the elements of the array in a new layout.

In the specific case of reshaping a 1-dimensional array into a 2-dimensional array with a single row (1 row and multiple columns), the reshaping process essentially adds an additional dimension to the array.

The reshaping step input_data_reshaped = input_data_as_np.reshape(1, -1) is performed to transform the 1-dimensional array into a 2-dimensional array with a single row and an automatically calculated number of columns. The reshape() function is used, where the first argument 1 indicates the desired number of rows (in this case, 1), and the second argument -1 indicates that the number of columns should be automatically determined based on the size of the original array.

This reshaping step is necessary because scikit-learn's predict() method expects the input data to be in a 2-dimensional format, where each row represents an individual sample and each column represents a feature. Reshaping the input data ensures that it is compatible with the model for making predictions.

After reshaping, input_data_reshaped will be a 2-dimensional NumPy array with a shape of (1, num_features), where num_features is the number of features in the original input data.

We can then pass input_data_reshaped to the predict() method of your trained logistic regression model to obtain predictions for this new data point.
"""

# predicting new unseen data
predictions = logreg.predict(input_data_reshaped)
print(predictions)

"""Our model accurately predicts the class as Benign. We carry out further comprehensive tests to be sure our model is performing well."""

# Calculate precision, recall, and F1 score
print(classification_report(y_test, y_pred))

# Calculate ROC AUC score
auc_score = roc_auc_score(y_test, y_pred)
print("ROC AUC Score:", auc_score)

"""Precision: For the "0" class, the model has a precision of 0.97, which means that 97% of the instances predicted as "0" are actually "0". For the "1" class, the precision is 0.95, indicating that 95% of the instances predicted as "1" are actually "1". Higher precision values indicate fewer false positives.

Recall: The "0" class has a recall of 0.91, meaning that the model correctly identifies 91% of the actual "0" instances. The "1" class has a recall of 0.99, indicating that the model captures 99% of the actual "1" instances. Higher recall values indicate fewer false negatives.

F1-Score: The F1-score considers both precision and recall. For the "0" class, the F1-score is 0.94, and for the "1" class, it is 0.97. The weighted average F1-score is 0.96, indicating a good overall balance between precision and recall.

Accuracy: The overall accuracy of the model is 0.96, which means that it correctly predicts the class label for 96% of the instances in the test data.

These metrics suggest that the logistic regression model is performing well in classifying both the "0" and "1" classes, with high precision, recall, and F1-score. The accuracy score confirms the model's overall effectiveness in predicting the class labels accurately.

The ROC AUC (Receiver Operating Characteristic Area Under the Curve) score is a metric that evaluates the performance of a binary classification model. It measures the ability of the model to distinguish between the positive and negative classes by analyzing the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity).

In this case, the ROC AUC score is 0.946, which indicates that the logistic regression model has a good discriminatory power. A score of 0.5 represents a random guess, while a score of 1.0 represents a perfect classifier.

A ROC AUC score of 0.946 suggests that the model performs well in distinguishing between the "0" and "1" classes, with a high true positive rate and a low false positive rate. This indicates that the model has a high probability of assigning higher predicted probabilities to the positive class compared to the negative class.

Overall, a ROC AUC score of 0.946 demonstrates that the logistic regression model is effective in classifying the instances and has a strong ability to discriminate between the two classes.

<h3>Conclusion<h3>

<p1>In conclusion, this project focused on utilizing logistic regression for the binary classification task of predicting breast tumor types as malignant or benign. By analyzing the Breast Cancer Wisconsin (Diagnostic) Dataset, we aimed to develop a model capable of accurately classifying tumors based on their characteristics.

Through data exploration, preprocessing, and model training, we built a logistic regression model and fine-tuned its hyperparameters to optimize performance. The evaluation metrics, including accuracy, precision, recall, and F1-score, were used to assess the model's effectiveness in correctly classifying tumors.

Overall, the logistic regression model demonstrated promising results, achieving a high level of accuracy and exhibiting good performance in different evaluation metrics. This suggests that logistic regression can be a valuable tool in aiding the diagnosis of breast cancer by classifying tumors as malignant or benign.

However, it is important to note that further analysis, validation, and refinement may be required before deploying the model in a real-world clinical setting. Additionally, exploring other classification algorithms, such as Support Vector Machines (SVMs), could provide valuable insights and potential improvements to the classification task.

In summary, this project contributes to the ongoing efforts in leveraging machine learning techniques for breast cancer diagnosis and emphasizes the potential of logistic regression as a reliable approach in this domain.<p1>
"""